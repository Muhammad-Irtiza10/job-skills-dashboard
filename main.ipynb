{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "682ccf8c",
   "metadata": {},
   "source": [
    "Python function to read a PDF and return its text content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c25b9e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "76 | P a g e  \n",
      " \n",
      " Catalog 2024-2025 \n",
      "SCHOOL OF ARTS AND SCIENCES \n",
      "Bachelor of Arts in Mass Communication \n",
      "The Bachelor of Arts degree in Mass Communication provides students with a high-quality education in line \n",
      "with emerging market trends in the media industry within the UAE, the Middle East, and the world. Rapid \n",
      "advancements in the field of communication and new media have created demand for qualified \n",
      "professionals and leaders who possess the knowledge to address global issues and, by so do\n"
     ]
    }
   ],
   "source": [
    "import fitz  # PyMuPDF library\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Read a PDF file and return all text content as a single string.\"\"\"\n",
    "    text = \"\"\n",
    "    with fitz.open(pdf_path) as doc:               # Open the PDF\n",
    "        for page in doc:                           # Iterate through pages\n",
    "            text += page.get_text(\"text\")          # Extract text from each page\n",
    "    return text\n",
    "\n",
    "# Example usage:\n",
    "pdf_path = r\"C:\\Users\\aurakcyber4\\job-skills-dashboard\\docs\\B.A. Degree in Mass Communication with Concentration in Digital Media.pdf\"          # Path to the university catalog PDF\n",
    "catalog_text = extract_text_from_pdf(pdf_path)\n",
    "print(catalog_text[:500])  # Print first 500 characters for a peek\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7f26d5",
   "metadata": {},
   "source": [
    "load spaCy and initialize the matcher:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bfb904b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")               # load English language model\n",
    "matcher = PhraseMatcher(nlp.vocab)               # initialize the PhraseMatcher\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2b60ad",
   "metadata": {},
   "source": [
    "list of skill terms (phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517090c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example skill terms (in practice, compile this list from your domain or text analysis)\n",
    "skill_terms = [\n",
    "    \"communication theory\", \n",
    "    \"critical thinking\", \n",
    "    \"analytical abilities\",\n",
    "    \"communication technology\",\n",
    "    \"research methodologies\",\n",
    "    \"multimedia practices\"\n",
    "]\n",
    "# Create pattern Doc objects for each term and add to the matcher\n",
    "patterns = [nlp.make_doc(term) for term in skill_terms]    # create Doc for each phrase\n",
    "matcher.add(\"SKILL_TERMS\", patterns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0709f0e",
   "metadata": {},
   "source": [
    "use the matcher on the catalog text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11e6038a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skills found: {'digital media', 'research methodologies', 'critical thinking'}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(catalog_text)                      # process the entire catalog text with spaCy\n",
    "matches = matcher(doc)                       # find all occurrences of the skill terms\n",
    "extracted_skills = set()                     # use a set to avoid duplicates\n",
    "for match_id, start, end in matches:\n",
    "    span = doc[start:end]                    # the matched span of text\n",
    "    extracted_skills.add(span.text.lower())  # collect the skill phrase (normalized to lowercase)\n",
    "print(\"Skills found:\", extracted_skills)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459710d8",
   "metadata": {},
   "source": [
    "RAKE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a0c9533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top RAKE phrases: ['media communication 3 comm 334 broadcast journalism 3 comm 323 news reporting 3 mass communication elective 3 gen ed natural science course 3 free elective 3 mass communication elective 3 free elective 3 subtotal', 'digital culture 3 comm 224 visual storytelling 3 comm 323 news reporting 3 comm 334 broadcast journalism 3 comm 423 interactive multimedia 3 80', 'behavioral science course 3 gen ed course mathematics course 3 gen ed course natural science course 3 program core course requirements 35 credits course', 'credits comm 213 public relations writing 3 comm 334 broadcast journalism 3 comm 337 public relations cases 3 comm 344 public relations', 'digital media 3 comm 212 media writing 3 comm 215 feature writing 3 comm 222 intercultural mass communication 3 comm 223 globalization', 'description cr com 212 media writing 3 comm 215 feature writing 3 comm 222 intercultural mass communication 3 comm 223 globalization', '3 free elective 3 mass communication elective 3 mass communication elective 3 free elective 3 subtotal', 'multimedia storytelling 3 comm 423 interactive multimedia 3 free elective 3 comm 450 selected topics', 'united arab emirates studies 3 mass communication elective 3 gen ed mathematics course 3 arab 210', 'digital culture 3 comm 224 visual storytelling 3 uaes 200 survey']\n"
     ]
    }
   ],
   "source": [
    "from rake_nltk import Rake\n",
    "\n",
    "# 1. Prepare RAKE as usual (stopwords already downloaded)\n",
    "rake_extractor = Rake()\n",
    "\n",
    "# 2. Split your catalog text into simple sentences yourself\n",
    "#    Here we split on periods — you can also split on '\\n' or use a regex.\n",
    "sentences = [s.strip() for s in catalog_text.split('.') if s]\n",
    "\n",
    "# 3. Give RAKE those sentences directly\n",
    "rake_extractor.extract_keywords_from_sentences(sentences)\n",
    "\n",
    "# 4. Pull out the top phrases\n",
    "key_phrases = rake_extractor.get_ranked_phrases()\n",
    "print(\"Top RAKE phrases:\", key_phrases[:10])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6f637a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered RAKE candidates: ['elective course', 'fifth writing intensive course', 'different mass communication fields', 'summer semester course', 'free electives', 'description cr course', 'description cr course', 'description cr course', 'description cr course', 'writing intensive course', 'mass communication provides students', 'mass communications degree requires', 'mass communication offers concentrations', 'native arabic learners course', 'native arabic learners course', 'mass communication program', 'news', 'program must meet requirements', 'concentration course requirements', 'general education component requirements']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def is_valid_phrase(phrase):\n",
    "    # no digits\n",
    "    if re.search(r'\\d', phrase):\n",
    "        return False\n",
    "    # no all-caps codes (like COMM, UAES)\n",
    "    if re.search(r'\\b[A-Z]{2,}\\b', phrase):\n",
    "        return False\n",
    "    # reasonable length: 1–4 words\n",
    "    word_count = len(phrase.split())\n",
    "    if word_count < 1 or word_count > 4:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "cleaned = [p for p in key_phrases if is_valid_phrase(p)]\n",
    "print(\"Filtered RAKE candidates:\", cleaned[:20])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9923e779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After blacklist filter: ['different mass communication fields', 'news']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Your RAKE candidates from the first filter\n",
    "candidates = [\n",
    "  'elective course',\n",
    "  'fifth writing intensive course',\n",
    "  'different mass communication fields',\n",
    "  'summer semester course',\n",
    "  'free electives',\n",
    "  'description cr course',\n",
    "  'writing intensive course',\n",
    "  'mass communication provides students',\n",
    "  'mass communications degree requires',\n",
    "  'mass communication offers concentrations',\n",
    "  'native arabic learners course',\n",
    "  'mass communication program',\n",
    "  'news',\n",
    "  'program must meet requirements',\n",
    "  'concentration course requirements',\n",
    "  'general education component requirements'\n",
    "]\n",
    "\n",
    "# Define blacklist terms\n",
    "blacklist = [\n",
    "    'course', 'program', 'require', 'elective', 'description',\n",
    "    'component', 'concentration', 'summer', 'free', 'degree', 'offers', 'provides'\n",
    "]\n",
    "\n",
    "def is_skill_candidate(phrase):\n",
    "    # reject if any blacklist term is present\n",
    "    if any(term in phrase for term in blacklist):\n",
    "        return False\n",
    "    # keep very short core words like \"news\"\n",
    "    return True\n",
    "\n",
    "filtered = [p for p in candidates if is_skill_candidate(p)]\n",
    "print(\"After blacklist filter:\", filtered)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "255073f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_terms = [\n",
    "    \"news reporting\",\n",
    "    \"broadcast journalism\",\n",
    "    \"public relations writing\",\n",
    "    \"multimedia storytelling\",\n",
    "    \"visual storytelling\",\n",
    "    \"digital media\",\n",
    "    \"interactive multimedia\",\n",
    "    \"media ethics\",\n",
    "    \"critical thinking\",\n",
    "    \"research methodologies\"\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea0f799c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# replace all whitespace (including newlines) with a single space\n",
    "catalog_text = re.sub(r'\\s+', ' ', catalog_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e11628a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final extracted skills: {'interactive multimedia', 'critical thinking', 'multimedia storytelling', 'visual storytelling', 'public relations writing', 'broadcast journalism', 'research methodologies', 'news reporting', 'digital media'}\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Create a matcher that compares the LOWER attribute of tokens\n",
    "matcher = PhraseMatcher(nlp.vocab, attr=\"LOWER\")\n",
    "\n",
    "\n",
    "# Build lowercase patterns\n",
    "patterns = [nlp.make_doc(term) for term in skill_terms]\n",
    "matcher.add(\"COURSE_SKILLS\", patterns)\n",
    "\n",
    "# Process cleaned text\n",
    "doc = nlp(catalog_text)\n",
    "\n",
    "# Extract matches\n",
    "found_skills = {doc[start:end].text.lower() for _id, start, end in matcher(doc)}\n",
    "print(\"Final extracted skills:\", found_skills)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5af5f5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"news reporting\" in catalog_text.lower()  # should be True if it’s there"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
